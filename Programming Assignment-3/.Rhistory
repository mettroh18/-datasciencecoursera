# the # of times the letter "e" appears in `my_intro`
occurrences <- str_count(my_intro, "e")
occurences
occurrences <- str_count(my_intro, "e")
occurrences
double <- function(value) {
answer <- value * 2
answer
}
# Using your `double()` function, create a variable `minutes_in_two_days`,
# which is the number of minutes in two days
minutes_in_two_days <- double(minutes_in_a_day)
minutes_in_two_days
# A2 foundational skills
# Set up and Defining variables ------------------------------------------------
# Load the the `stringr` package
# (you'll need to install it if you haven't used it before)
# It has a variety of functions that make working with string variables easier
library(stringr)
# Create a numeric variable `my_age` that is equal to your age
my_age <- 19
# Create a variable `my_name` that is equal to your first name
my_name <- "Rohini"
# Using multiplication, create a variable `minutes_in_a_day` that is
# equal to the number of minutes in a day
minutes_in_a_day <- 60 * 24
# Using multiplication, create a variable `hours_in_a_year` that is
# equal to the number of hours in a year
hours_in_a_year <- 24 * 365
# Create a variable `more_minutes_than_hours` that is boolean (TRUE/FALSE)
# It should be TRUE if there are more minutes/day than hours/year
# Otherwise it should be FALSE
more_minutes_than_hours <- minutes_in_a_day > hours_in_a_year
# Working with functions -------------------------------------------------------
# Write a function `make_introduction()` that takes in two args (`name`, `age`)
# This function should return a string value that says:
# Hello, my name is {name}, and I'm {age} years old.
# The values {name} and {age} should take on the values passed into the function
# Make sure that proper spacing is used (e.g., you shouldn't have multiple
# spaces between words, and you should a space after a comma)
make_introduction <- function(name, age) {
answer <- paste("Hello, my name is ", name, ", and I'm ", age, " years old.")
answer
}
# Create a variable `my_intro` by passing your variables `my_name` and `my_age`
# into your `make_introduction()` function
my_intro <- make_introduction(my_name, my_age)
my_intro
# Create a variable `casual_intro` by substituting "Hello, my name is",
# with "Hey, I'm" in your `my_intro` variable
casual_intro <- gsub("Hello, my name is ", "Hey, I'm ", my_intro)
casual_intro
# Create a variable `loud_intro`, which is `my_intro` in all upper-case letters
# You should do this by using a function to convert your `my_intro` variable
# into all capital letters.
loud_intro <- str_to_upper(my_intro)
loud_intro
# Create a variable `quiet_intro`, which is `my_intro` in all lower-case letters
# You should do this by using a function to convert your `my_intro` variable
# into all lower-case letters.
quiet_intro <- str_to_lower(my_intro)
quiet_intro
# Create a new variable `capitalized_intro`, which is your `my_intro` variable,
# but with each word capitalized. hint: use the stringr function `str_to_title`
capitalized_intro <- str_to_title(my_intro)
# Using the `str_count` function, create a variable `occurrences` that stores
# the # of times the letter "e" appears in `my_intro`
occurrences <- str_count(my_intro, "e")
occurrences
# Write a function `double()` that takes in a value and
# returns that value times two
double <- function(value) {
answer <- value * 2
answer
}
# Using your `double()` function, create a variable `minutes_in_two_days`,
# which is the number of minutes in two days
minutes_in_two_days <- double(minutes_in_a_day)
minutes_in_two_days
# Write a function `cube()` that takes in a value and returns that value cubed
cube <- function(value) {
answer <- value * value * value
answer
}
# Create a variable `twenty_seven` by passing 3 to your `cube()` function
twenty_seven <- cube(3)
twenty_seven
# Create a function `inches_to_cm` that converts from inches to centimeters
inches_to_cm <- function(inches) {
cm <- inches * 2.54
cm
}
inches_to_cm <- function(inches) {
cm <- inches * 2.54
cm
}
# Create a variable `inches_tall` that is your (numeric) height in inches
inches_tall <- 61
# Using your `inches_to_cm` function and your `inches_tall` variable,
# create a variable `cm_tall` that is your height in centimeters
cm_tall <- inches_to_cm(inches_tall)
cm_tall
has_more_zs <- function(a, b) {
a_num <- gsub("z", "", a) #Removes Zs
b_num <- gsub("z", "", b)
a_z <- nchar(a) - nchar(a_num) #Counts how many Zs were removed
b_z <- nchar(b) - nchar(b_num)
if (a_num == a && b_num == b) {
answer <- answer <- "Neither string contains the letter z"
} else if (a_z > b_z) {
answer <- a
} else if (b_z > a_z) {
answer <- b
} else if (a_z == b_z) {
answer <- "The strings have the same number of Zs"
}
answer
}
# Create a variable `more_zs` by passing two strings of your choice to your
# `has_more_zs` function
more_zs <- has_more_zs("pizza", "zipper")
more_zs
more_zs <- has_more_zs("pizza", "zipperz")
more_zs
movies <- c(
"Aladdin", "Endgame", "The Intern",
"Italian Job", "Her", "Arrival"
)
# Create a vector `top_three` that only contains the first three movies
# You should do this by subsetting the vector, not by simply retyping the movies
top_three <- movies[c(1, 2, 3)]
top_three
excited <- paste(movies, " is a great movie!")
excited
without_four <- movies[-4]
without_four
x <- 1:1000
Students <- paste("Student", x)
math_grades <- rnorm(1000, mean = 88, sd = 10)
a <- math_grades > 100
math_grades[a] = 100
spanish_grades <- rnorm(1000, mean = 85, sd = 12)
b <- spanish_grades > 100
spanish_grades[b] = 100
grades <- data.frame(Students, math_grades, spanish_grades)
num_students <- nrow(grades)
# Create a variable `num_courses` that contains the number of columns
# in your dataframe `grades` minus one (b/c of their names)
num_courses <- ncol(grades)
grades["grade_diff"] <- students$math_grades - students$spanish_grades
x <- 1:1000
students <- paste("Student", x)
math_grades <- rnorm(1000, mean = 88, sd = 10)
a <- math_grades > 100
math_grades[a] = 100
spanish_grades <- rnorm(1000, mean = 85, sd = 12)
b <- spanish_grades > 100
spanish_grades[b] = 100
grades <- data.frame(students, math_grades, spanish_grades)
num_students <- nrow(grades)
num_courses <- ncol(grades) - 1
grades["grade_diff"] <- students$math_grades - students$spanish_grades
grades["grade_diff"] <- students[math_grades] - students[spanish_grades]
grades["grade_diff"] <- students$math_grades - students$spanish_grades
grades["grade_diff"] <- math_grades - spanish_grades
grades[better_at_math] <- math_grades > spanish_grades
grades["better_at_math"] <- math_grades > spanish_grades
View(grades)
View(grades)
num_better_at_math <- length(grades["better_at_math"])
num_better_at_math <- length(grades["better_at_math"] == TRUE)
View(grades)
num_better_at_math <- length(better_at_math)
x <- grades["better_at_math"] == TRUE
num_better_at_math <- length(x)
x <- grades["better_at_math"]
num_better_at_math <- length(x)
num_better_at_math <- length(students[x])
install.packages("carData")
nrow(Florida[GORE > BUSH,])
library(carData)
nrow(Florida[GORE > BUSH,])
nrow(Florida[,Florida$GORE > Florida$BUSH])
Florida[Florida$GORE > Florida$BUSH,]
nrow(Florida[Florida$GORE > Florida$BUSH,])
a <- Florida[Florida$GORE > Florida$BUSH,]
sum(a[NADER])
a <- Florida[Florida$GORE > Florida$BUSH,]
sum(a[[NADER]])
a <- Florida[Florida$GORE > Florida$BUSH,]
sum(a[Florida$NADER])
a <- Florida[Florida$GORE > Florida$BUSH,]
sum(a$NADER)
rownames(Florida[Florida$Total == max(Florida$Total),])
rownames(Florida[Florida$Total = max(Florida$Total),])
rownames(Florida$Total[Florida$Total == max(Florida$Total),])
rownames(Florida[Florida$Total == min(Florida$Total),])
install.packages("nycflights13") # once per machine
library("nycflights13")
most_early <- flights %>%
group_by(dest) %>% # group by destination
summarize(delay = mean(arr_delay))
View("nycflights13")
library("nycflights13")
?flights          # read the available documentation
dim(flights)      # check the number of rows/columns
colnames(flights) # inspect the column names
View(flights)     # look at the data frame in the RStudio Viewer
gather(flights, "dest", "arr_delay")
install.packages("dplyr") # once per machine
library("dplyr")
gather(flights, "dest", "arr_delay")
max(flights$arr_delay)
has_most_delays <- flights %>%            # start with the flights
group_by(dest) %>%                   # group by airline (carrier)
filter(dep_delay > 0) %>%               # find only the delays
summarize(num_delay = n()) %>%          # count the observations
filter(num_delay == max(num_delay)) %>% # find most delayed
select(dest)
has_most_delays
View(diamonds)
library("ggplot2")
View(diamonds)
library("ggplot2")
ggplot(data =diamonds) +
geom_point(mapping = aes(x = carat, y = price, color = clarity))
ggplot(data = diamonds) +
geom_point(mapping = aes(x = cut, y = clarity))
ggplot(data = diamonds) +
geom_col(mapping = aes(x = cut, y = price, fill = clarity))
ggplot(data = diamonds) +
geom_col(mapping = aes(x = cut, y = price, fill = clarity), position = "fill")
ggplot(data = diamonds) +
geom_col(mapping = aes(x = cut, y = price, fill = clarity), position = "dodge")
ggplot(data = diamonds) +
geom_point(mapping = aes(x = carat, y = price, color = clarity)) +
scale_color_brewer("BrBG") + facet_wrap(~ color)
library(readr)
height.data <- read_tsv('https://sites.williams.edu/rdeveaux/files/2011/08/Galton.txt')
population <- height.data$Child
mean(population)
sd(population)
set.seed(123)
sample.20 <- sample(population, size=20, replace=TRUE)
mean(sample.20)
set.seed(555)
many.samples <- replicate(10000, mean(sample(population, size=20, replace=TRUE)))
mean(many.samples)
sd(many.samples)
quantile(many.samples, 0.025)
quantile(many.samples, 0.025)
quantile(many.samples, 0.975)
barplot(table(many.samples))
2.517941 / sqrt(20)
2.517941 + 2(0.5630287)
2.517941 - 2(0.5630287)
2.517941 + 2*0.5630287
2.517941 - 2*0.5630287
2.517941 + (2*0.5630287)
2.517941 - (2*0.5630287)
68.08847 + (2*0.5630287)
68.08847 - (2*0.5630287)
sum(many.samples<67)
sum(many.samples<67)
sum(many.samples<69)
sum(many.samples<67)
271/10000
set.seed(555)
many.samples.size.5 <- replicate(10000, mean(sample(population, size=5, replace=TRUE)))
sum(many.samples.size.5 < 67)
1506/10000
set.seed(111)
sample.count <- rbinom(n=1, size=50, p=0.07)
mean(sample.count)
sample.count
set.seed(333)
many.phats <- replicate(10000, rbinom(1, size=50, p=0.07)/50)
barplot(table(many.phats))
set.seed(333)
many.phats <- replicate(10000, rbinom(1, size=50, p=0.07))
barplot(table(many.phats))
set.seed(333)
many.phats <- replicate(10000, rbinom(1, size=50, p=0.07)/50)
barplot(table(many.phats))
set.seed(333)
many.phats2 <- replicate(10000, rbinom(1, size=150, p=0.07)/50)
barplot(table(many.phats2))
quantile(many.phats2, 0.025)
quantile(many.phats2, 0.975)
set.seed(333)
many.phats2 <- replicate(10000, rbinom(1, size=150, p=0.07))
barplot(table(many.phats2))
#19: 0.1
#20: 0.34
quantile(many.phats2, 0.025)
quantile(many.phats2, 0.975)
lower.bound <- quantile(many.phats2, 0.025)
upper.bound <- quantile(many.phats2, 0.975)
#21:
sum(many.phats > lower.bound & many.phats < upper.bound)/length(many.phats)
set.seed(333)
many.phats <- replicate(10000, rbinom(1, size=50, p=0.07)/50)
barplot(table(many.phats))
#18: chart has more bars bc larger sample size = more variability
# Looks normal
set.seed(333)
many.phats2 <- replicate(10000, rbinom(1, size=150, p=0.07)/50)
barplot(table(many.phats2))
lower.bound <- quantile(many.phats2, 0.025)
upper.bound <- quantile(many.phats2, 0.975)
sum(many.phats > lower.bound & many.phats < upper.bound)/length(many.phats)
pnorm(many.samples, mean =68.08847 , sd = 0.5630287)
library(readr)
height.data <- read_tsv('https://sites.williams.edu/rdeveaux/files/2011/08/Galton.txt')
population <- height.data$Child
mean(population) #1 - 68.08847
sd(population) #2 - 2.517941
#set.seed makes sure everyone gets the same numbers from random sampling code
set.seed(123)
sample.20 <- sample(population, size=20, replace=TRUE)
mean(sample.20) #3 - 67.6
set.seed(555)
many.samples <- replicate(10000, mean(sample(population, size=20, replace=TRUE)))
mean(many.samples) #4 - 68.07971
sd(many.samples) #5 - 0.5606293
#6,7 : Find theoretical mean  and SD
#theoretical mean = population mean = 68.08847
#sd = population sd / sqrt (20) = 2.517941 / sqrt(20) = 0.5630287
2.517941 / sqrt(20)
#8: 66.96241
#9: 69.21453
68.08847 + (2*0.5630287)
68.08847 - (2*0.5630287)
quantile(many.samples, 0.025) #10 - 66.95
quantile(many.samples, 0.975) #11 - 69.175
barplot(table(many.samples))
#12: Yes, 3?
#13
pnorm(many.samples, mean =68.08847 , sd = 0.5630287)
#14 = 271 / 10,000 = 0.0271 = 2.71%
sum(many.samples<67)
#14: 1506 / 10000 = 15.06%
set.seed(555)
many.samples.size.5 <- replicate(10000, mean(sample(population, size=5, replace=TRUE)))
sum(many.samples.size.5 < 67)
#15: Option 4
#16
set.seed(111)
sample.count <- rbinom(n=1, size=50, p=0.07)
#sample.count = 4 --> 4/50 = 0.08 = 8%
#17: no,4
set.seed(333)
many.phats <- replicate(10000, rbinom(1, size=50, p=0.07)/50)
barplot(table(many.phats))
#18: chart has more bars bc larger sample size = more variability
# Looks normal
set.seed(333)
many.phats2 <- replicate(10000, rbinom(1, size=150, p=0.07)/50)
barplot(table(many.phats2))
#19: 0.1 / 5
#20: 0.34 / 17
lower.bound <- quantile(many.phats2, 0.025)
upper.bound <- quantile(many.phats2, 0.975)
#21: 0.1396
sum(many.phats > lower.bound & many.phats < upper.bound)/length(many.phats)
#22: 1
pnorm(many.samples, mean =68.08847 , sd = 0.5630287)
pnorm(67, mean =68.08847 , sd = 0.5630287)
install.packages("BSDA")
library(BSDA)
library(readr)
#load father son data set
height.data <- read_tsv('https://sites.williams.edu/rdeveaux/files/2011/08/Galton.txt')
child.heights <- height.data$Child
parent.heights <- height.data$Parent
set.seed(111)
#selects 30 random numbers 1:928
selected.pairs <- sample(1:928, size=30)
#uses selected.pairs vector to choose 30 samples from each set
child.sample <- child.heights[selected.pairs]
parent.sample <- parent.heights[selected.pairs]
#We have access to the population sd, so we can compute a
#z-score for the mean height of all children in the population
pop.sd <- sd(child.heights)
test1 <- z.test(child.sample, sigma.x = pop.sd, conf.level=0.95)
test1$conf.int
test3 <- z.test(child.sample, alternative="greater", mu=68.0, sigma.x = pop.sd, conf.level=0.95)
test3
#load data
ceo.salaries <- read_tsv("https://sites.williams.edu/rdeveaux/files/2014/09/CEO_Salary_2012.txt")
population.salary <- ceo.salaries$`1-Year Pay ($mil)`
hist(population.salary)
mean(population.salary)
sd(population.salary)
set.seed(111)
many.intervals <- replicate(100000, z.test(
sample(population.salary, size=10),
sigma.x = pop.sd,
conf.level = 0.90)$conf.int
)
lower.bounds <-many.intervals[1,]
upper.bounds <- many.intervals[2,]
num_correct <- sum(lower.bounds < pop.mean & pop.mean < upper.bounds)
pop.mean <- mean(population.salary)
pop.sd <- sd(population.salary)
set.seed(111)
many.intervals <- replicate(100000, z.test(
sample(population.salary, size=10),
sigma.x = pop.sd,
conf.level = 0.90)$conf.int
)
lower.bounds <-many.intervals[1,]
upper.bounds <- many.intervals[2,]
num_correct <- sum(lower.bounds < pop.mean & pop.mean < upper.bounds)
num_correct
93124 / 10000
93124 / 100000
set.seed(111)
many.intervals2 <- replicate(100000, z.test(
sample(population.salary, size=100),
sigma.x = pop.sd,
conf.level = 0.90)$conf.int
)
lower.bounds <-many.intervals2[1,]
upper.bounds <- many.intervals2[2,]
num_correct <- sum(lower.bounds < pop.mean & pop.mean < upper.bounds)
set.seed(111)
many.intervals <- replicate(100000, z.test(
sample(population.salary, size=10),
sigma.x = pop.sd,
conf.level = 0.90)$conf.int
)
lower.bounds <-many.intervals[1,]
upper.bounds <- many.intervals[2,]
num_correct <- sum(lower.bounds < pop.mean & pop.mean < upper.bounds)
set.seed(111)
many.intervals2 <- replicate(100000, z.test(
sample(population.salary, size=100),
sigma.x = pop.sd,
conf.level = 0.90)$conf.int
)
lower.bounds2 <-many.intervals2[1,]
upper.bounds2 <- many.intervals2[2,]
num_correct2 <- sum(lower.bounds2 < pop.mean & pop.mean < upper.bounds2)
num_correct2
setwd("~/CoursEra/datasciencecoursera/Programming Assignment-3")
if(!file.exists("/dataset")) {dir.create("./dataset")}
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL, destfile = "./data/downloaded.csv", method = "curl")
train1 <- list.files(path="./data/train/Inertial-Signals", pattern="body_acc", full.names=TRUE)
train2 <- list.files(path="./data/train/Inertial-Signals", pattern="body_gyro", full.names=TRUE)
train3 <- list.files(path="./data/train/Inertial-Signals", pattern="total_acc", full.names=TRUE)
trainA <- merge(train1, all = TRUE)
trainB <- merge(train2, all = TRUE)
trainC <- merge(train3, all = TRUE)
training <- read.csv("./data/train/X_train.csv")
test <- read.csv("./data/test/X_test.csv")
setwd("~/CoursEra/datasciencecoursera/Programming Assignment-3")
library(plyr)
library(dplyr)
library(readr)
training <- read.csv("./data/train/X_train.csv")
test <- read.csv("./data/test/X_test.csv")
training <- readtext("./data/train/X_train.txt")
test <- readtext("./data/test/X_test.txt")
install.packages("readtext")
library(readtext)
training <- readtext("./data/train/X_train.txt")
test <- readtext("./data/test/X_test.txt")
View(training)
training <- read.table("./data/train/X_train.txt",
header = FALSE)
test <- read.table("./data/test/X_test.txt",
header = FALSE)
View(test)
View(test)
training <- readtext("./data/train/X_train.txt")
test <- readtext("./data/test/X_test.txt")
merged <- data.frame(training, test)
View(merged)
typeof(training)
training <- readtext("./data/train/X_train.txt")
test <- readtext("./data/test/X_test.txt")
dataset <- rbind(training, test)
features <- read.table("data/features.txt")$V2
names(dataset) <- features
#Extracts only the measurements on the mean and standard deviation for each measurement.
filtered <- grepl("std|mean", features) & !grepl("meanFreq", features)
dataset <- dataset[filtered]
rm(features, filtered)
#Label each row by its appropriate subject
subjects1 <- read.table("data/train/subject_train.txt")
subjects2 <- read.table("data/test/subject_test.txt")
allsubjects <- rbind(subjects1, subjects2)
names(labels) <- c("Subject")
dataset <- cbind(allsubjects, dataset)
rm(subjects1, subjects2, allsubjects)
#Uses descriptive activity names to name the activities in the data set
labels1 <- read.table("data/train/y_train.txt")
labels2 <- read.table("data/test/y_test.txt")
activities <- rbind(labels1, labels2)
code <- read.table("data/activity_labels.txt")
activities <- (lapply(activities, function(x) code[x,2]))
activities <- as.data.frame(activities)
names(activities) <- c("Activity")
dataset <- cbind(activities, dataset)
rm(labels1, labels2, code, activities)
#From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
tidydata <- dataset %>%
group_by(Activity, Subject) %>%
summarize_all(funs(mean))
write.table(tidy, file = "./tidy.txt", row.names = FALSE)
